#!/usr/bin/env python3
"""
ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿè£…ã—ãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åŸºæœ¬æ©Ÿèƒ½ã‚’æ¤œè¨¼
"""
import sys
import json
from pathlib import Path
from datetime import datetime
import asyncio

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.scraping.result_exporter import ResultExporter, BatchResult, ScrapingResult, ResultStatus, ExportFormat
from src.scraping.error_handler import ErrorHandler, RetryConfig, ScrapingError

def validate_result_exporter():
    """çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼ã®æ¤œè¨¼"""
    print("ğŸ” çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼æ¤œè¨¼")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    test_dir = project_root / 'logs' / 'validation_test'
    test_dir.mkdir(parents=True, exist_ok=True)
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
    exporter = ResultExporter(test_dir)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    batch_result = BatchResult(
        batch_id="validation_test",
        started_at=datetime.now()
    )
    
    # ãƒ†ã‚¹ãƒˆçµæœè¿½åŠ 
    test_results = [
        ScrapingResult(
            n_code="N02306",
            title="ãƒ‘ãƒ©ãƒ¬ã‚¤ãƒ‰ãƒ‡ã‚¤ã‚ºâ‘£",
            site_name="Amazon Kindle", 
            status=ResultStatus.SUCCESS,
            url="https://example.com/test1"
        ),
        ScrapingResult(
            n_code="N02307",
            title="ã‚¨ã‚¢ãƒœãƒ¼ãƒ³ã‚¦ã‚¤ãƒƒãƒâ‘£",
            site_name="æ¥½å¤©Kobo",
            status=ResultStatus.NOT_FOUND,
            error_message="æ¤œç´¢çµæœãªã—"
        )
    ]
    
    for result in test_results:
        batch_result.add_result(result)
    
    batch_result.finalize()
    
    # å„å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    formats_tested = []
    for format in [ExportFormat.JSON, ExportFormat.CSV]:
        try:
            output_path = exporter.export_batch_result(batch_result, format=format)
            print(f"  âœ… {format.value.upper()}å‡ºåŠ›æˆåŠŸ: {output_path.name}")
            formats_tested.append(format.value)
        except Exception as e:
            print(f"  âŒ {format.value.upper()}å‡ºåŠ›å¤±æ•—: {e}")
    
    # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
    try:
        summary_path = exporter.export_summary_report([batch_result])
        print(f"  âœ… ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆæˆåŠŸ: {summary_path.name}")
    except Exception as e:
        print(f"  âŒ ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
    
    print(f"  ğŸ“Š çµ±è¨ˆ: æˆåŠŸç‡ {batch_result.success_rate:.1f}%")
    return True

async def validate_error_handler():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®æ¤œè¨¼"""
    print("ğŸ” ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼æ¤œè¨¼")
    
    error_handler = ErrorHandler()
    
    # æˆåŠŸã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ
    async def success_function():
        return "Success!"
    
    try:
        result = await error_handler.execute_with_retry(success_function)
        print(f"  âœ… æˆåŠŸã‚±ãƒ¼ã‚¹: {result}")
    except Exception as e:
        print(f"  âŒ æˆåŠŸã‚±ãƒ¼ã‚¹å¤±æ•—: {e}")
        return False
    
    # ãƒªãƒˆãƒ©ã‚¤ãƒ†ã‚¹ãƒˆ
    attempt_count = [0]
    
    async def failing_then_success():
        attempt_count[0] += 1
        if attempt_count[0] < 3:
            raise ScrapingError(f"Test error (attempt {attempt_count[0]})")
        return "Success after retries"
    
    try:
        retry_config = RetryConfig(max_attempts=5, base_delay=0.1)
        result = await error_handler.execute_with_retry(
            failing_then_success,
            retry_config=retry_config
        )
        print(f"  âœ… ãƒªãƒˆãƒ©ã‚¤æˆåŠŸ: {result}")
    except Exception as e:
        print(f"  âŒ ãƒªãƒˆãƒ©ã‚¤å¤±æ•—: {e}")
        return False
    
    # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
    health_report = error_handler.get_health_report()
    print(f"  ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§: {health_report.get('overall_health', 'unknown')}")
    
    return True

def validate_scrapers():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®åŸºæœ¬æ¤œè¨¼"""
    print("ğŸ” ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åŸºæœ¬æ©Ÿèƒ½æ¤œè¨¼")
    
    try:
        from src.scraping.amazon_kindle_scraper import AmazonKindleScraper
        from src.scraping.rakuten_kobo_scraper import RakutenKoboScraper
        from src.scraping.google_play_books_scraper import GooglePlayBooksScraper
        
        scrapers = [
            ("Amazon Kindle", AmazonKindleScraper),
            ("æ¥½å¤©Kobo", RakutenKoboScraper),
            ("Google Play Books", GooglePlayBooksScraper)
        ]
        
        for name, scraper_class in scrapers:
            try:
                scraper = scraper_class(headless=True)
                print(f"  âœ… {name}ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–æˆåŠŸ")
                
                # ã‚¿ã‚¤ãƒˆãƒ«æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆ
                test_title = "ãƒ‘ãƒ©ãƒ¬ã‚¤ãƒ‰ãƒ‡ã‚¤ã‚ºâ‘£"
                normalized = scraper.normalize_title(test_title)
                print(f"    ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«æ­£è¦åŒ–: {test_title} â†’ {normalized}")
                
                # å·»æ•°æŠ½å‡ºãƒ†ã‚¹ãƒˆ
                volume = scraper.extract_volume_number(test_title)
                print(f"    ğŸ“– å·»æ•°æŠ½å‡º: {test_title} â†’ ç¬¬{volume}å·»")
                
                # ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆãƒ†ã‚¹ãƒˆ
                variants = scraper.create_volume_variants(test_title)
                print(f"    ğŸ”„ ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {len(variants)}")
                
            except Exception as e:
                print(f"  âŒ {name}ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–å¤±æ•—: {e}")
                
    except ImportError as e:
        print(f"  âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
        return False
    
    return True

def validate_google_sheets():
    """Google Sheetsã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¤œè¨¼"""
    print("ğŸ” Google Sheetsã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¤œè¨¼")
    
    try:
        from src.scraping.google_sheets_client_updated import GoogleSheetsClient, SalesChannel
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        credentials_path = project_root / 'config' / 'credentials' / 'google-sheets-key.json'
        if not credentials_path.exists():
            print(f"  âš ï¸  èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {credentials_path}")
            print("  ğŸ“ Google Sheetsæ¥ç¶šãƒ†ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return True
        
        # åŸºæœ¬çš„ãªåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
        spreadsheet_id = '1hMhDw3HJsUMetceMvy2lszDeLCxarNavn_2E6Inf84M'
        client = GoogleSheetsClient(str(credentials_path), spreadsheet_id)
        print("  âœ… GoogleSheetsClientåˆæœŸåŒ–æˆåŠŸ")
        
        # åˆ—æŒ™å‹ãƒ†ã‚¹ãƒˆ
        channels = list(SalesChannel)
        print(f"  ğŸ“Š è²©å£²ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(channels)}")
        
        return True
        
    except ImportError as e:
        print(f"  âŒ Google Sheetsã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")
        return False
    except Exception as e:
        print(f"  âŒ Google Sheetsã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å¤±æ•—: {e}")
        return False

async def main():
    """ãƒ¡ã‚¤ãƒ³æ¤œè¨¼å‡¦ç†"""
    print("=== IzumiNovels-Workflow ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ¤œè¨¼ ===")
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    results = []
    
    # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æ¤œè¨¼
    results.append(("çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼", validate_result_exporter()))
    results.append(("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼", await validate_error_handler()))
    results.append(("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åŸºæœ¬æ©Ÿèƒ½", validate_scrapers()))
    results.append(("Google Sheetsã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ", validate_google_sheets()))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n=== æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼ ===")
    passed = 0
    total = len(results)
    
    for component, result in results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
        print(f"{component}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ“Š å…¨ä½“çµæœ: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
    else:
        print("âš ï¸  ä¸€éƒ¨ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)