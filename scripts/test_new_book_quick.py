#!/usr/bin/env python3
"""
æ–°ã—ã„æ›¸ç±ã€Œã‚¯ã‚½ã‚²ãƒ¼æ‚ªå½¹ä»¤å¬¢â‘ æ–°è£…ç‰ˆã€ã§ã®
3ã¤ã®é«˜é€Ÿã‚µã‚¤ãƒˆï¼ˆebookjapan, honto, Apple Booksï¼‰ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
"""
import asyncio
import sys
import json
from pathlib import Path
from datetime import datetime
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.scraping.ebookjapan_scraper import EbookjapanScraper
from src.scraping.honto_scraper import HontoScraper
from src.scraping.apple_books_scraper import AppleBooksLinkGenerator

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


async def test_new_book():
    """æ–°æ›¸ç±ã§ã®é«˜é€Ÿã‚µã‚¤ãƒˆãƒ†ã‚¹ãƒˆ"""
    
    # æ–°ã—ã„æ›¸ç±æƒ…å ±
    test_book = {
        'n_code': 'N02402',
        'title': 'ã‚¯ã‚½ã‚²ãƒ¼æ‚ªå½¹ä»¤å¬¢â‘ æ–°è£…ç‰ˆ',
        'description': 'å®Ÿéš›ã®ãªã‚ã†ä½œå“ï¼ˆã‚·ãƒ¼ãƒˆæœªè¨­å®šï¼‰'
    }
    
    print("=== æ–°æ›¸ç±ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ ===")
    print(f"ãƒ†ã‚¹ãƒˆæ›¸ç±: {test_book['title']} ({test_book['n_code']})")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("å¯¾è±¡: é«˜é€Ÿ3ã‚µã‚¤ãƒˆï¼ˆebookjapan, honto, Apple Booksï¼‰")
    print()
    
    # é«˜é€Ÿã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼è¨­å®š
    scrapers = [
        (EbookjapanScraper, "ebookjapan", "ğŸ¥‡ 100%æˆåŠŸåŸºæº–"),
        (HontoScraper, "honto", "âœ¨ ebookjapanç¶™æ‰¿"),
        (AppleBooksLinkGenerator, "Apple Books", "ğŸ¯ iTunes API")
    ]
    
    results = {}
    
    # å„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    for scraper_class, scraper_name, description in scrapers:
        print(f"\nğŸ“‹ {scraper_name}: {description}")
        
        start_time = datetime.now()
        
        try:
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–ï¼ˆã‚µã‚¤ãƒˆåˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            if scraper_name == "Apple Books":
                scraper = scraper_class(timeout=15, max_retries=2)
            else:
                scraper = scraper_class(timeout=15, max_retries=2)
            
            async with scraper:
                # Apple Booksç”¨ç‰¹æ®Šå¯¾å¿œï¼ˆISBNãªã—ï¼‰
                if scraper_name == "Apple Books":
                    url = await scraper.search_book(test_book['title'], test_book['n_code'], "")
                else:
                    url = await scraper.search_book(test_book['title'], test_book['n_code'])
                
                end_time = datetime.now()
                processing_time = (end_time - start_time).total_seconds()
                
                if url:
                    print(f"  âœ… æˆåŠŸ: {url}")
                    print(f"  â±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
                    success = True
                else:
                    print(f"  âŒ è¦‹ã¤ã‹ã‚‰ãš")
                    print(f"  â±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
                    success = False
                
                results[scraper_name] = {
                    'url': url,
                    'success': success,
                    'processing_time': processing_time,
                    'timestamp': end_time.isoformat()
                }
                
        except Exception as e:
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            print(f"  ğŸ’¥ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            print(f"  â±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
            
            results[scraper_name] = {
                'url': None,
                'success': False,
                'error': str(e),
                'processing_time': processing_time,
                'timestamp': end_time.isoformat()
            }
        
        # ã‚µã‚¤ãƒˆé–“å¾…æ©Ÿ
        await asyncio.sleep(2)
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print("ğŸ¯ æ–°æ›¸ç±ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ")
    print(f"{'='*60}")
    
    successful_sites = [name for name, result in results.items() if result['success']]
    failed_sites = [name for name, result in results.items() if not result['success']]
    
    overall_success_rate = len(successful_sites) / len(results) * 100
    avg_time = sum(r['processing_time'] for r in results.values()) / len(results)
    
    print(f"ğŸ“š æ›¸ç±: {test_book['title']}")
    print(f"ğŸ¯ ç·åˆæˆç¸¾: {len(successful_sites)}/{len(results)} ({overall_success_rate:.1f}%)")
    print(f"âš¡ å¹³å‡æ™‚é–“: {avg_time:.1f}ç§’")
    print()
    print("ğŸ“Š ã‚µã‚¤ãƒˆåˆ¥çµæœ:")
    
    for scraper_name, result in results.items():
        if result['success']:
            emoji = "âœ…"
            status = f"{result['processing_time']:.1f}s"
        else:
            emoji = "âŒ"
            status = f"å¤±æ•— ({result['processing_time']:.1f}s)"
        
        print(f"  {emoji} {scraper_name:15}: {status}")
    
    # æˆåŠŸã‚µã‚¤ãƒˆè©³ç´°
    if successful_sites:
        print(f"\nâœ… æˆåŠŸã‚µã‚¤ãƒˆè©³ç´°:")
        for site in successful_sites:
            result = results[site]
            print(f"  - {site}: {result['url']}")
    
    # å¤±æ•—ã‚µã‚¤ãƒˆè©³ç´°
    if failed_sites:
        print(f"\nâŒ å¤±æ•—ã‚µã‚¤ãƒˆè©³ç´°:")
        for site in failed_sites:
            result = results[site]
            error = result.get('error', 'è¦‹ã¤ã‹ã‚‰ãš')
            print(f"  - {site}: {error}")
    
    # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
    print(f"\nğŸ“Š ä»–æ›¸ç±ã¨ã®æ¯”è¼ƒ:")
    print(f"  SAO, ã‚¹ãƒ©ã‚¤ãƒ : ebookjapan 100%, honto 100%, Apple Books 100%")
    print(f"  ã‚¯ã‚½ã‚²ãƒ¼æ‚ªå½¹ä»¤å¬¢: ebookjapan {('100%' if 'ebookjapan' in successful_sites else '0%')}, honto {('100%' if 'honto' in successful_sites else '0%')}, Apple Books {('100%' if 'Apple Books' in successful_sites else '0%')}")
    
    if overall_success_rate >= 80:
        print(f"  ğŸ‰ Excellent! é«˜ã‚¹ã‚³ã‚¢é”æˆ")
    elif overall_success_rate >= 60:
        print(f"  ğŸ“ˆ Good! æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
    else:
        print(f"  ğŸ¤” è¦èª¿æŸ»: æ–°æ›¸ç±ã§ã®æ¤œç´¢ç²¾åº¦èª²é¡Œ")
    
    print(f"\n=== æ–°æ›¸ç±ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº† ===")
    return results


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        await test_new_book()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    asyncio.run(main())