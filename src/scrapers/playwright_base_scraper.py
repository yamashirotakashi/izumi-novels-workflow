"""
Unified async scraper architecture using Playwright with comprehensive type safety.

This module provides the async version of the unified base scraper, designed
to work alongside the sync version with consistent interfaces and type hints.
"""

from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, Protocol, TypeVar, Generic, Union, AsyncContextManager
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime
import json
import time
import random
import asyncio

# Playwright imports
from playwright.async_api import async_playwright, Browser, BrowserContext, Page, Playwright


# Import shared types from the base scraper
from .base_scraper import BookInfo, ScrapingResult, ScrapingProtocol


class AsyncScrapingProtocol(Protocol):
    """Protocol defining the async interface for all scrapers."""
    
    site_id: str
    site_name: str
    
    async def search_books(self, query: str) -> ScrapingResult:
        """Search for books with the given query."""
        ...
    
    async def cleanup(self) -> None:
        """Clean up resources."""
        ...


class AsyncBaseScraper(ABC):
    """
    Unified async base scraper using Playwright with comprehensive type safety.
    
    This provides the async counterpart to BaseScraper, offering better performance
    for concurrent scraping operations while maintaining the same interface.
    """
    
    def __init__(self, site_id: str, site_name: str) -> None:
        self.site_id: str = site_id
        self.site_name: str = site_name
        self.playwright: Optional[Playwright] = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.config: Dict[str, Any] = self._load_config()
        self.site_config: Dict[str, Any] = self.config.get('sites', {}).get(site_id, {})
        self.max_retries: int = 3
        self.timeout: int = 30000  # 30ç§’ï¼ˆPlaywrightã¯ãƒŸãƒªç§’ï¼‰
        
    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from file with proper error handling."""
        config_path: Path = Path(__file__).parent.parent.parent / "config" / "site_selectors.json"
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    async def setup_browser(self, headless: bool = True) -> None:
        """Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— - Chrome for Testingçµ±åˆç‰ˆ"""
        try:
            self.playwright = await async_playwright().start()
            
            # Chrome for Testingç›´æ¥æŒ‡å®šã§ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•
            self.browser = await self.playwright.chromium.launch(
                executable_path='/opt/chrome-for-testing/chrome-linux64/chrome',
                headless=headless,
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor',
                    '--single-process',  # WSL2ã§ã®å®‰å®šæ€§å‘ä¸Š
                    '--disable-software-rasterizer',
                    '--disable-extensions',
                    '--disable-plugins',
                    '--disable-default-apps',
                    '--no-first-run',
                    '--disable-background-timer-throttling',
                    '--disable-backgrounding-occluded-windows',
                    '--disable-renderer-backgrounding',
                    '--disable-features=TranslateUI',
                    '--disable-ipc-flooding-protection',
                ]
            )
            
            # ãƒ–ãƒ©ã‚¦ã‚¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36'
            )
            
            # ãƒšãƒ¼ã‚¸ä½œæˆ
            self.page = await self.context.new_page()
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
            self.page.set_default_timeout(self.timeout)
            
            print(f"âœ… {self.site_name} Playwrightãƒ–ãƒ©ã‚¦ã‚¶æº–å‚™å®Œäº†")
            
        except Exception as e:
            print(f"âŒ Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            await self.cleanup()
            raise
    
    async def human_like_delay(self, min_delay: float = 1.0, max_delay: float = 3.0) -> None:
        """äººé–“ã‚‰ã—ã„å¾…æ©Ÿæ™‚é–“"""
        delay: float = random.uniform(min_delay, max_delay)
        await asyncio.sleep(delay)
    
    async def human_like_typing(self, selector: str, text: str) -> None:
        """äººé–“ã‚‰ã—ã„ã‚¿ã‚¤ãƒ”ãƒ³ã‚°"""
        if not self.page:
            raise RuntimeError("Page not initialized")
            
        await self.page.fill(selector, "")  # ã‚¯ãƒªã‚¢
        for char in text:
            await self.page.type(selector, char, delay=random.uniform(50, 150))
    
    async def find_element_flexible(self, selectors: List[str], timeout: int = 10000) -> Any:
        """æŸ”è»Ÿãªè¦ç´ æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰"""
        if not self.page:
            raise RuntimeError("Page not initialized")
            
        for i, selector in enumerate(selectors):
            try:
                element = await self.page.wait_for_selector(selector, timeout=timeout)
                if i > 0:
                    print(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚»ãƒ¬ã‚¯ã‚¿ä½¿ç”¨: {selector}")
                return element
            except Exception:
                continue
        
        raise Exception(f"å…¨ã‚»ãƒ¬ã‚¯ã‚¿ã§è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {selectors}")
    
    async def safe_get_text(self, selector: str) -> str:
        """å®‰å…¨ãªãƒ†ã‚­ã‚¹ãƒˆå–å¾—"""
        if not self.page:
            return ""
            
        try:
            element = await self.page.wait_for_selector(selector, timeout=5000)
            if element:
                return await element.text_content() or ""
        except:
            pass
        return ""
    
    async def safe_get_attribute(self, selector: str, attribute: str) -> str:
        """å®‰å…¨ãªå±æ€§å–å¾—"""
        if not self.page:
            return ""
            
        try:
            element = await self.page.wait_for_selector(selector, timeout=5000)
            if element:
                return await element.get_attribute(attribute) or ""
        except:
            pass
        return ""
    
    @abstractmethod
    async def search_books(self, query: str) -> ScrapingResult:
        """æ›¸ç±æ¤œç´¢å®Ÿè¡Œï¼ˆå„ã‚µã‚¤ãƒˆå®Ÿè£…å¿…é ˆï¼‰"""
        pass
    
    async def cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self.page:
                await self.page.close()
                print(f"âœ… {self.site_name} ãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ã‚º")
            
            if self.context:
                await self.context.close()
                print(f"âœ… {self.site_name} ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒ­ãƒ¼ã‚º")
            
            if self.browser:
                await self.browser.close()
                print(f"âœ… {self.site_name} ãƒ–ãƒ©ã‚¦ã‚¶ã‚¯ãƒ­ãƒ¼ã‚º")
            
            if self.playwright:
                await self.playwright.stop()
                print(f"âœ… {self.site_name} Playwrightã‚¹ãƒˆãƒƒãƒ—")
        
        except Exception as e:
            print(f"âš ï¸ {self.site_name} ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def scrape_with_retry(self, query: str) -> ScrapingResult:
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ"""
        start_time: float = time.time()
        last_error: Optional[str] = None
        
        for attempt in range(self.max_retries + 1):
            try:
                if attempt > 0:
                    print(f"ğŸ”„ {self.site_name} ãƒªãƒˆãƒ©ã‚¤ {attempt}/{self.max_retries}")
                    await self.human_like_delay(2.0, 4.0)  # ãƒªãƒˆãƒ©ã‚¤å‰ã«é•·ã‚ã®å¾…æ©Ÿ
                
                result: ScrapingResult = await self.search_books(query)
                result.execution_time = time.time() - start_time
                result.retry_count = attempt
                
                if result.success:
                    print(f"âœ… {self.site_name} ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸ ({attempt + 1}å›ç›®)")
                    return result
                else:
                    last_error = result.error_message
                    
            except Exception as e:
                last_error = str(e)
                print(f"âŒ {self.site_name} ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ{attempt + 1}): {e}")
        
        # å…¨è©¦è¡Œå¤±æ•—
        execution_time: float = time.time() - start_time
        return ScrapingResult(
            site_name=self.site_name,
            site_id=self.site_id,
            query=query,
            success=False,
            books_found=[],
            error_message=f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°({self.max_retries})è¶…é: {last_error}",
            execution_time=execution_time,
            retry_count=self.max_retries
        )
    
    async def __aenter__(self) -> AsyncBaseScraper:
        """Async Context Managerå¯¾å¿œ"""
        await self.setup_browser()
        return self
    
    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:
        """Async Context Managerçµ‚äº†å‡¦ç†"""
        await self.cleanup()


# Legacy compatibility - keep PlaywrightBaseScraper as alias
PlaywrightBaseScraper = AsyncBaseScraper